{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import uuid\n",
    "import datetime\n",
    "import warnings\n",
    "\n",
    "from itertools import product\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import tqdm\n",
    "import netCDF4\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as pl\n",
    "\n",
    "from numba import jit, int32\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def convective_radius(ze_bkg, area_relation):\n",
    "    \"\"\"\n",
    "    Given a mean background reflectivity value, we determine via a step\n",
    "    function what the corresponding convective radius would be\n",
    "    Higher background reflectivitives are expected to have larger convective\n",
    "    influence on surrounding areas, so a larger convective radius would be\n",
    "    prescribed\n",
    "    \"\"\"\n",
    "    if (area_relation == 0):\n",
    "        if (ze_bkg < 30):\n",
    "            conv_rad = 1000.\n",
    "        elif (ze_bkg >= 30) & (ze_bkg < 35.):\n",
    "            conv_rad = 2000.\n",
    "        elif (ze_bkg >= 35.) & (ze_bkg < 40.):\n",
    "            conv_rad = 3000.\n",
    "        elif (ze_bkg >= 40.) & (ze_bkg < 45.):\n",
    "            conv_rad = 4000.\n",
    "        else:\n",
    "            conv_rad = 5000.\n",
    "\n",
    "    if (area_relation == 1):\n",
    "        if (ze_bkg < 25):\n",
    "            conv_rad = 1000.\n",
    "        elif (ze_bkg >= 25) & (ze_bkg < 30.):\n",
    "            conv_rad = 2000.\n",
    "        elif (ze_bkg >= 30.) & (ze_bkg < 35.):\n",
    "            conv_rad = 3000.\n",
    "        elif (ze_bkg >= 35.) & (ze_bkg < 40.):\n",
    "            conv_rad = 4000.\n",
    "        else:\n",
    "            conv_rad = 5000.\n",
    "\n",
    "    if (area_relation == 2):\n",
    "        if (ze_bkg < 20):\n",
    "            conv_rad = 1000.\n",
    "        elif (ze_bkg >= 20) & (ze_bkg < 25.):\n",
    "            conv_rad = 2000.\n",
    "        elif (ze_bkg >= 25.) & (ze_bkg < 30.):\n",
    "            conv_rad = 3000.\n",
    "        elif (ze_bkg >= 30.) & (ze_bkg < 35.):\n",
    "            conv_rad = 4000.\n",
    "        else:\n",
    "            conv_rad = 5000.\n",
    "\n",
    "    if (area_relation == 3):\n",
    "        if (ze_bkg < 40):\n",
    "            conv_rad = 0.\n",
    "        elif (ze_bkg >= 40) and (ze_bkg < 45.):\n",
    "            conv_rad = 1000.\n",
    "        elif (ze_bkg >= 45.) and (ze_bkg < 50.):\n",
    "            conv_rad = 2000.\n",
    "        elif (ze_bkg >= 50.) and (ze_bkg < 55.):\n",
    "            conv_rad = 6000.\n",
    "        else:\n",
    "            conv_rad = 8000.\n",
    "\n",
    "    return conv_rad\n",
    "\n",
    "@jit(nopython=True)\n",
    "def peakedness(ze_bkg, peak_relation):\n",
    "    \"\"\"\n",
    "    Given a background reflectivity value, we determine what the necessary\n",
    "    peakedness (or difference) has to be between a grid point's reflectivity\n",
    "    and the background reflectivity in order for that grid point to be labeled\n",
    "    convective\n",
    "    \"\"\"\n",
    "    if (peak_relation == 0):\n",
    "        if (ze_bkg < 0.):\n",
    "            peak = 10.\n",
    "        elif (ze_bkg >= 0.) and (ze_bkg < 42.43):\n",
    "            peak = 10. - ze_bkg ** 2 / 180.\n",
    "        else:\n",
    "            peak = 0.\n",
    "\n",
    "    elif (peak_relation == 1):\n",
    "        if (ze_bkg < 0.):\n",
    "            peak = 14.\n",
    "        elif (ze_bkg >= 0.) and (ze_bkg < 42.43):\n",
    "            peak = 14. - ze_bkg ** 2 / 180.\n",
    "        else:\n",
    "            peak = 4.\n",
    "\n",
    "    return peak\n",
    "\n",
    "@jit(nopython=True)\n",
    "def steiner_classification(refl, x, y, dx, dy, intense=42, peak_relation=0,\n",
    "                           area_relation=1, bkg_rad=11000, use_intense=True):\n",
    "    \"\"\"\n",
    "    We perform the Steiner et al. (1995) algorithm for echo classification\n",
    "    using only the reflectivity field in order to classify each grid point\n",
    "    as either convective, stratiform or undefined. Grid points are classified\n",
    "    as follows,\n",
    "    0 = Undefined\n",
    "    1 = Stratiform\n",
    "    2 = Convective\n",
    "\n",
    "    Parameters:\n",
    "    ===========\n",
    "    refl: ndarray\n",
    "        Reflectivity slice (2D Cartesion grid).\n",
    "    x: ndarray\n",
    "        x-coordinates\n",
    "    y: ndarray\n",
    "        y-coordinates\n",
    "    dx: float\n",
    "        x-coordinates resolution\n",
    "    dy: float\n",
    "        y-coordinates resolution\n",
    "    intense: float\n",
    "        Value above which a pixel is consider convective no matter what.\n",
    "\n",
    "    Returns:\n",
    "    ========\n",
    "    sclass: ndarray <int>\n",
    "        Convective/Stratiform classification, same size as refl.\n",
    "    \"\"\"\n",
    "\n",
    "    sclass = np.zeros(refl.shape, dtype=int32)\n",
    "    ny, nx = refl.shape\n",
    "\n",
    "    for i in range(0, nx):\n",
    "        # Get stencil of x grid points within the background radius\n",
    "        imin = np.max(np.array([1, (i - bkg_rad / dx)], dtype=int32))\n",
    "        imax = np.min(np.array([nx, (i + bkg_rad / dx)], dtype=int32))\n",
    "\n",
    "        for j in range(0, ny):\n",
    "            # First make sure that the current grid point has not already been classified.\n",
    "            # This can happen when grid points within the convective radius of a previous\n",
    "            # grid point have also been classified\n",
    "            if ~np.isnan(refl[j, i]) & (sclass[j, i] == 0):\n",
    "                # Get stencil of y grid points within the background radius\n",
    "                jmin = np.max(np.array([1, (j - bkg_rad / dy)], dtype=int32))\n",
    "                jmax = np.min(np.array([ny, (j + bkg_rad / dy)], dtype=int32))\n",
    "\n",
    "                n = 0\n",
    "                sum_ze = 0\n",
    "\n",
    "                # Calculate the mean background reflectivity for the current grid point,\n",
    "                # which will be used to determine the convective radius and the required peakedness\n",
    "\n",
    "                for l in range(imin, imax):\n",
    "                    for m in range(jmin, jmax):\n",
    "                        rad = np.sqrt((x[l] - x[i]) ** 2 + (y[m] - y[j]) ** 2)\n",
    "\n",
    "                        # The mean background reflectivity will first be computed in\n",
    "                        # linear units, i.e. mm^6/m^3, then converted to decibel units.\n",
    "                        if rad <= bkg_rad:\n",
    "                            n += 1\n",
    "                            sum_ze += 10. ** (refl[m, l] / 10.)\n",
    "\n",
    "                ze_bkg = 10.0 * np.log10(sum_ze / n)\n",
    "\n",
    "                # Now get the corresponding convective radius knowing the mean background reflectivity\n",
    "                conv_rad = convective_radius(ze_bkg, area_relation)\n",
    "\n",
    "                # Now we want to investigate the points surrounding the current\n",
    "                # grid point that are within the convective radius, and whether\n",
    "                # they too are convective, stratiform or undefined\n",
    "\n",
    "                # Get stencil of x and y grid points within the convective radius\n",
    "                lmin = np.max(np.array([1, int(i - conv_rad / dx)]))\n",
    "                lmax = np.min(np.array([nx, int(i + conv_rad / dx)]))\n",
    "                mmin = np.max(np.array([1, int(j - conv_rad / dy)]))\n",
    "                mmax = np.min(np.array([ny, int(j + conv_rad / dy)]))\n",
    "\n",
    "                if use_intense and (refl[j, i] >= intense):\n",
    "                    sclass[j, i] = 2\n",
    "\n",
    "                    for l in range(lmin, lmax):\n",
    "                        for m in range(mmin, mmax):\n",
    "                            if not np.isnan(refl[j, i]):\n",
    "                                rad = np.sqrt((x[l] - x[i]) ** 2 + (y[m] - y[j]) ** 2)\n",
    "\n",
    "                                if rad <= conv_rad:\n",
    "                                    sclass[m, l] = 2\n",
    "\n",
    "                else:\n",
    "                    peak = peakedness(ze_bkg, peak_relation)\n",
    "\n",
    "                    if refl[j, i] - ze_bkg >= peak:\n",
    "                        sclass[j, i] = 2\n",
    "\n",
    "                        for l in range(imin, imax):\n",
    "                            for m in range(jmin, jmax):\n",
    "                                if not np.isnan(refl[j, i]):\n",
    "                                    rad = np.sqrt((x[l] - x[i]) ** 2 + (y[m] - y[j]) ** 2)\n",
    "\n",
    "                                    if rad <= conv_rad:\n",
    "                                        sclass[m, l] = 2\n",
    "\n",
    "                    else:\n",
    "                        # If by now the current grid point has not been classified as convective\n",
    "                        # by either the intensity criteria or the peakedness criteria, then it must be stratiform\n",
    "                        sclass[j, i] = 1\n",
    "\n",
    "    return sclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_list(input_dir):\n",
    "    '''\n",
    "    Generate file list.\n",
    "    \n",
    "    Parameter:\n",
    "    ===========\n",
    "    input_dir: str\n",
    "        Path to input data directory\n",
    "        \n",
    "    Returns:\n",
    "    ========\n",
    "    flist: list\n",
    "        Input file list.\n",
    "    '''\n",
    "    flist = sorted(glob.glob(os.path.join(input_dir, '*.nc')))\n",
    "    if len(flist) == 144:\n",
    "        return flist\n",
    "    \n",
    "    flist = [None] * 144\n",
    "    for cnt, (h, m) in enumerate(product(range(0, 24), range(0, 6))):\n",
    "            infiles = glob.glob(os.path.join(input_dir, f'*_{h:02}{m}*.nc'))\n",
    "            if len(infiles) == 0:\n",
    "                continue\n",
    "\n",
    "            infile = infiles[0]\n",
    "            if os.path.isfile(infile):\n",
    "                flist[cnt] = infile\n",
    "    \n",
    "    return flist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_metadata(gnrl_meta):\n",
    "    '''\n",
    "    Correct general metadata dictionnary.\n",
    "    \n",
    "    Parameters:\n",
    "    ===========\n",
    "    gnrl_meta: dict\n",
    "        General metadata dictionnary.\n",
    "        \n",
    "    Returns:\n",
    "    ========\n",
    "    gnrl_meta: dict\n",
    "        Updated general metadata dictionnary.\n",
    "    '''\n",
    "    maxlon = '132.3856852067545'\n",
    "    minlon = '129.70320368213441'\n",
    "    maxlat = '-10.941777804922253'\n",
    "    minlat = '-13.552905831511362'\n",
    "    latres = '0.0225'\n",
    "\n",
    "    origin_altitude = '50'\n",
    "    origin_latitude = '-12.249'\n",
    "    origin_longitude = '131.044'\n",
    "    projection = 'Azimuthal equidistant projection'\n",
    "\n",
    "    obsolete_keys = ['original_format', 'n_gates_vary', 'driver', 'start_datetime', \n",
    "                     'start_time', 'end_datetime', 'end_time', 'scan_name', 'scan_id', \n",
    "                     'ray_times_increase', 'Conventions', 'Sub_conventions']\n",
    "    for key in obsolete_keys:\n",
    "        try:\n",
    "            gnrl_meta.pop(key)\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "    gnrl_meta['version'] = '2018.06_level2'\n",
    "    gnrl_meta['created'] = datetime.datetime.now().isoformat()\n",
    "    gnrl_meta['uuid'] = str(uuid.uuid4())\n",
    "    gnrl_meta['processing_level'] = 'L2'\n",
    "\n",
    "    gnrl_meta['geospatial_bounds'] = f\"({minlon}, {maxlon}, {minlat}, {maxlat})\"\n",
    "    gnrl_meta['geospatial_lat_min'] = minlat\n",
    "    gnrl_meta['geospatial_lat_max'] = maxlat\n",
    "    gnrl_meta['geospatial_lat_units'] = \"degrees_north\"\n",
    "    gnrl_meta['geospatial_lat_resolution'] = latres\n",
    "    gnrl_meta['geospatial_lon_min'] = minlon\n",
    "    gnrl_meta['geospatial_lon_max'] = maxlon\n",
    "    gnrl_meta['geospatial_lon_units'] = \"degrees_east\"\n",
    "    gnrl_meta['geospatial_lon_resolution'] = latres\n",
    "#     gnrl_meta['geospatial_vertical_min'] = '0'\n",
    "#     gnrl_meta['geospatial_vertical_max'] = '20000'\n",
    "#     gnrl_meta['geospatial_vertical_resolution'] = '500'\n",
    "#     gnrl_meta['geospatial_vertical_units'] = \"meters\"\n",
    "    gnrl_meta['origin_latitude'] = origin_latitude\n",
    "    gnrl_meta['origin_longitude'] = origin_longitude\n",
    "    gnrl_meta['origin_altitude'] = origin_altitude\n",
    "    gnrl_meta['geospatial_projection'] = projection\n",
    "    \n",
    "    return gnrl_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(input_file, data_key='radar_estimated_rain_rate', level=0, bad=-9999):\n",
    "    '''\n",
    "    Read netCDF4 file, data, data metadata, and file metadata.\n",
    "    \n",
    "    Parameters:\n",
    "    ===========\n",
    "    input_file: str\n",
    "        Input file name.\n",
    "    data_key: str\n",
    "        Data moment name\n",
    "        \n",
    "    Returns:\n",
    "    ========\n",
    "    data: ndarray\n",
    "        Data\n",
    "    data_meta: dict\n",
    "        Data metadata\n",
    "    gnrl_meta: dict\n",
    "        File metadata\n",
    "    '''\n",
    "    try:\n",
    "        with netCDF4.Dataset(input_file) as ncid:\n",
    "            data = np.squeeze(ncid[data_key][:, level, :, :]).filled(bad)\n",
    "            data_meta_nc = ncid[data_key]\n",
    "\n",
    "            data_meta = dict()\n",
    "            for key in data_meta_nc.ncattrs():\n",
    "                data_meta[key] = data_meta_nc.getncattr(key)\n",
    "\n",
    "            gnrl_meta = dict()\n",
    "            for key in ncid.ncattrs():\n",
    "                gnrl_meta[key] = ncid.getncattr(key)\n",
    "    except Exception:\n",
    "        print(input_file)\n",
    "        raise\n",
    "            \n",
    "    return data, data_meta, gnrl_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir(mydir):\n",
    "    if os.path.exists(mydir):\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        os.mkdir(mydir)\n",
    "    except FileExistsError:\n",
    "        return None\n",
    "    \n",
    "    return None        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dailys(inargs):\n",
    "    x, y, date, INDIR, OUTDIR, MOMENT_NAME, RMAX, level, bad, XDIM, YDIM = inargs\n",
    "    \n",
    "    if MOMENT_NAME == 'steiner_echo_classification':\n",
    "        is_steiner = True\n",
    "    else:\n",
    "        is_steiner = False\n",
    "    \n",
    "    # Check if input dir exits.\n",
    "    indir = os.path.join(INDIR, str(date.year), date.strftime('%Y%m%d'))\n",
    "    if not os.path.exists(indir):\n",
    "        print(f'Input dir {indir} does not exist.')\n",
    "        return None\n",
    "    flist = get_file_list(indir)\n",
    "    \n",
    "    # Generate output file name\n",
    "    outdir = os.path.join(OUTDIR, MOMENT_NAME.upper())\n",
    "    mkdir(outdir)\n",
    "    outfilename = os.path.join(outdir, 'CPOL_{}_{}.nc'.format(MOMENT_NAME.upper(), date.strftime('%Y%m%d')))\n",
    "    if os.path.exists(outfilename):\n",
    "        print(f'Output file {outfilename} already exists. Doing nothing.')\n",
    "        return None\n",
    "    \n",
    "    if XDIM is None:\n",
    "        XDIM = len(x)\n",
    "    if YDIM is None:\n",
    "        YDIM = len(y)\n",
    "    \n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    R = np.sqrt(X ** 2 + Y ** 2)\n",
    "    \n",
    "    # Read data\n",
    "    RAIN_TOT = np.zeros((144, XDIM, YDIM))\n",
    "    for cnt, infile in enumerate(flist):\n",
    "        if infile is None:\n",
    "            RAIN_TOT[cnt, :, :] = np.NaN\n",
    "            continue\n",
    "        if is_steiner:\n",
    "            try:\n",
    "                rain, rain_meta, gnrl_meta = read_data(infile, 'reflectivity', level=level, bad=bad)\n",
    "            except Exception:\n",
    "                print(infile)\n",
    "                raise\n",
    "        else:\n",
    "            rain, rain_meta, gnrl_meta = read_data(infile, MOMENT_NAME, level=level, bad=bad)\n",
    "        rain[R >= RMAX] = np.NaN\n",
    "        RAIN_TOT[cnt, :, :] = rain\n",
    "\n",
    "    RAIN_TOT = np.ma.masked_where(np.isnan(RAIN_TOT), RAIN_TOT)\n",
    "    gnrl_meta = update_metadata(gnrl_meta)   \n",
    "    \n",
    "    # Generate time dimension\n",
    "    st = np.array(date, dtype=np.datetime64)\n",
    "    ed = np.array(date, dtype=np.datetime64) +  np.timedelta64(1,'D')\n",
    "    dtime = np.arange(st, ed, np.timedelta64(10, 'm'))  # Every 10 minutes\n",
    "    time_unit = f'seconds since {str(dtime[0])}'\n",
    "    time = netCDF4.date2num(dtime.tolist(), time_unit).astype(np.int32)\n",
    "    \n",
    "    # Write data\n",
    "    with netCDF4.Dataset(outfilename, 'w') as ncid:\n",
    "        ncid.createDimension('time', 144)\n",
    "        ncid.createDimension(\"longitude\", XDIM)\n",
    "        ncid.createDimension(\"latitude\", YDIM)\n",
    "\n",
    "        mymoment = ncid.createVariable(MOMENT_NAME, RAIN_TOT.dtype, (\"time\", \"latitude\", \"longitude\"), zlib=True)\n",
    "\n",
    "        nctime = ncid.createVariable('time', time.dtype, 'time')\n",
    "        nclon = ncid.createVariable('longitude', LON.dtype, ('longitude'))\n",
    "        nclat = ncid.createVariable('latitude', LAT.dtype, ('latitude'))\n",
    "        nclon[:] = LON\n",
    "        nclon.units = 'degrees_east'\n",
    "        nclat[:] = LAT\n",
    "        nclat.units = 'degrees_north'\n",
    "#         ncx = ncid.createVariable('x', x.dtype, 'x')\n",
    "#         ncy = ncid.createVariable('y', y.dtype, 'y')\n",
    "\n",
    "        nctime[:] = time\n",
    "        nctime.units = time_unit\n",
    "#         ncx[:] = x\n",
    "#         ncx.units = 'km'\n",
    "#         ncy[:] = y\n",
    "#         ncy.units = 'km'\n",
    "        \n",
    "        # Write attributes\n",
    "        mymoment[:] = RAIN_TOT\n",
    "        for k, v in rain_meta.items():\n",
    "            if k == '_FillValue':\n",
    "                continue\n",
    "            try:\n",
    "                mymoment.setncattr(str(k), str(v))\n",
    "            except AttributeError:\n",
    "                print(k)\n",
    "                print(v)\n",
    "                print(type(k))\n",
    "                print(type(v))\n",
    "                raise\n",
    "\n",
    "        for k, v  in gnrl_meta.items():\n",
    "            ncid.setncattr(k, str(v))\n",
    "            \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XDIM = 117\n",
    "# YDIM = 117\n",
    "# RMAX = 140\n",
    "# MOMENT_NAME = 'steiner_echo_classification'\n",
    "# OUTDIR = '/g/data2/rr5/vhl548/NEW_CPOL_level_2'\n",
    "# INDIR = '/g/data2/rr5/vhl548/CPOL_level_1b/GRIDDED/GRID_150km_2500m/'\n",
    "\n",
    "# x = np.linspace(-145, 145, XDIM, dtype=np.float32)\n",
    "# y = np.linspace(-145, 145, YDIM, dtype=np.float32)\n",
    "\n",
    "XDIM = 141\n",
    "YDIM = 141\n",
    "RMAX = 140\n",
    "MOMENT_NAME = 'steiner_echo_classification'\n",
    "OUTDIR = '/g/data2/rr5/vhl548/NEW_CPOL_level_2_1km'\n",
    "INDIR = '/g/data2/rr5/vhl548/CPOL_level_1b/GRIDDED/GRID_70km_1000m/'\n",
    "\n",
    "x = np.linspace(-70, 70, XDIM, dtype=np.float32)\n",
    "y = np.linspace(-70, 70, YDIM, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if XDIM == 117:\n",
    "    fdlatlon = '/g/data2/rr5/vhl548/CPOL_level_1b/GRIDDED/GRID_150km_2500m/2017/20170304/CPOL_20170304_0000_GRIDS_2500m.nc'\n",
    "else:\n",
    "    fdlatlon = '/g/data2/rr5/vhl548/CPOL_level_1b/GRIDDED/GRID_70km_1000m/2017/20170304/CPOL_20170304_0000_GRIDS_1000m.nc'\n",
    "\n",
    "with netCDF4.Dataset(fdlatlon) as ncid:\n",
    "    mylat = np.squeeze(ncid['latitude'][:].filled(np.NaN))\n",
    "    mylon = np.squeeze(ncid['longitude'][:].filled(np.NaN))\n",
    "\n",
    "if XDIM == 117:\n",
    "    LAT = mylat[0, :, 58]\n",
    "    LON = mylon[0, 58, :]\n",
    "else:\n",
    "    LAT = mylat[0, :, 70]\n",
    "    LON = mylon[0, 70, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range = pd.date_range('19981206', '20170502')\n",
    "# args_list = [None] * len(date_range)\n",
    "args_list = []\n",
    "for cnt, dt in enumerate(date_range):\n",
    "    indir = os.path.join(INDIR, str(dt.year), dt.strftime('%Y%m%d'))\n",
    "    if not os.path.exists(indir):\n",
    "        continue\n",
    "    args_list.append((x, y, dt, INDIR, OUTDIR, MOMENT_NAME, RMAX, 0, 0, XDIM, YDIM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df5b00f042af4e50b429022170455182",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2625), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "time.sleep(1500)\n",
    "with Pool(16) as pool:\n",
    "    rslt = list(tqdm.tqdm_notebook(pool.imap(make_dailys, args_list), total=len(args_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:radar]",
   "language": "python",
   "name": "conda-env-radar-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
